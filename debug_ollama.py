#!/usr/bin/env python3
"""Debug script for testing the Ollama generator locally."""

import asyncio
import traceback

from askme.core.config import get_settings
from askme.generation.generator import LocalOllamaGenerator, Passage


async def test_ollama() -> None:
    print("ğŸ” Testing Ollama Generator...")

    settings = get_settings()
    generator = LocalOllamaGenerator(settings.generation)

    passages = [
        Passage(
            doc_id="test-1",
            title="å‡¡äººä¿®ä»™ä¼ ",
            content="éŸ©ç«‹æ˜¯ä¸€ä¸ªä¿®ä»™è€…ï¼Œä»é’ç‰›é•‡å‡ºå‘å¼€å§‹ä¿®ä»™ä¹‹è·¯ã€‚",
            score=1.0,
        ),
        Passage(
            doc_id="test-2",
            title="ä¿®ç‚¼å†ç¨‹",
            content="ä»–é€šè¿‡åŠªåŠ›ä¿®ç‚¼ï¼Œä»ç‚¼æ°”æœŸå¼€å§‹ï¼Œé€æ­¥æå‡ä¿®ä¸ºã€‚",
            score=0.9,
        ),
    ]

    question = "éŸ©ç«‹æ˜¯è°ï¼Ÿ"

    try:
        print(f"ğŸ“ Question: {question}")
        print(f"ğŸ“š Passages: {len(passages)} documents")
        print(
            f"ğŸ”§ Config: {settings.generation.ollama_model} @ "
            f"{settings.generation.ollama_endpoint}"
        )

        print("ğŸš€ Generating answer...")
        answer = await generator.generate(question, passages)

        print(f"âœ… Answer: {answer}")
        print(f"ğŸ“ Answer length: {len(answer)} characters")

    except Exception as exc:
        print(f"âŒ Error: {exc}")
        print("ğŸ” Traceback:")
        traceback.print_exc()
    finally:
        await generator.cleanup()


if __name__ == "__main__":
    asyncio.run(test_ollama())
